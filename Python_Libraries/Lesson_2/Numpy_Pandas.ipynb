{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычисления с помощью Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Импортируйте библиотеку Numpy и дайте ей псевдоним np.\n",
    "Создайте массив Numpy под названием a размером 5x2, то есть состоящий из 5 строк и 2 столбцов. \n",
    "Первый столбец должен содержать числа 1, 2, 3, 3, 1, а второй - числа 6, 8, 11, 10, 7. \n",
    "Будем считать, что каждый столбец - это признак, а строка - наблюдение. \n",
    "Затем найдите среднее значение по каждому признаку, используя метод mean массива Numpy. \n",
    "Результат запишите в массив mean_a, в нем должно быть 2 элемента.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "a = np.array([[1,6],[2,8],[3,11],[3,10],[1,7]], int)\n",
    "print(a)\n",
    "print(f\"Среднее по первому признаку: {a[:, :1].mean()}\")\n",
    "print(f\"Среднее по второму признаку: {a[:, 1:2].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Вычислите массив a_centered, отняв от значений массива “а” средние значения соответствующих признаков, \n",
    "содержащиеся в массиве mean_a. \n",
    "Вычисление должно производиться в одно действие. \n",
    "Получившийся массив должен иметь размер 5x2.\n",
    "\"\"\"\n",
    "mean_a = np.array([a[:, :1].mean(), a[:, 1:].mean()], float)\n",
    "a_centered = a - mean_a\n",
    "print(a_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Найдите скалярное произведение столбцов массива a_centered.\n",
    "В результате должна получиться величина a_centered_sp.\n",
    "Затем поделите a_centered_sp на N-1, где N - число наблюдений.\n",
    "\"\"\"\n",
    "a_centered_sp = np.dot(a_centered[:, :1].reshape(5), a_centered[:, 1:].reshape(5))\n",
    "print(f\"Скалярное произведение: {a_centered_sp}\")\n",
    "print(f\"Отношение: {a_centered_sp / (a_centered.shape[0]-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "В этом задании проверьте получившееся число, вычислив ковариацию еще одним способом - с помощью функции np.cov. \n",
    "В качестве аргумента m функция np.cov должна принимать транспонированный массив “a”. \n",
    "В получившейся ковариационной матрице (массив Numpy размером 2x2) искомое значение ковариации \n",
    "будет равно элементу в строке с индексом 0 и столбце с индексом 1.\n",
    "\"\"\"\n",
    "print(f\"Ковариация: {np.cov(a.T)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с данными в Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Импортируйте библиотеку Pandas и дайте ей псевдоним pd. \n",
    "Создайте датафрейм authors со столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] \n",
    "и ['Тургенев', 'Чехов', 'Островский'].\n",
    "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно содержатся данные: \n",
    "[1, 1, 1, 2, 2, 3, 3], \n",
    "['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "[450, 300, 350, 500, 450, 370, 290].\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "authors = pd.DataFrame({\n",
    "    'author_id': [1,2,3],\n",
    "    'author_name': ['Тургенев', 'Чехов', 'Островский']\n",
    "})\n",
    "book = pd.DataFrame({\n",
    "    'author_id': [1, 1, 1, 2, 2, 3, 3],\n",
    "    'book_title': ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "    'price': [450, 300, 350, 500, 450, 370, 290]\n",
    "    \n",
    "})\n",
    "display(authors)\n",
    "display(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id\n",
    "\"\"\"\n",
    "authors_price = book.merge(authors, on='author_id')\n",
    "authors_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими книгами.\n",
    "\"\"\"\n",
    "top5 = authors_price.sort_values('price', ascending=False).head()\n",
    "top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца:\n",
    "author_name, min_price, max_price и mean_price,\n",
    "в которых должны содержаться соответственно имя автора,минимальная, максимальная и средняя цена на книги этого автора.\n",
    "\"\"\"\n",
    "authors_stat = pd.pivot_table(authors_price, index=['author_name'], values=['price'], \n",
    "                       aggfunc={'price':[min, max, np.mean]}).rename(\n",
    "    columns={\"max\":\"max_price\",\"min\":\"min_price\",\"mean\":\"mean_price\"})\n",
    "\n",
    "authors_stat.columns = authors_stat.columns.droplevel(0)\n",
    "authors_stat.columns.name = None               \n",
    "authors_stat = authors_stat.reset_index() \n",
    "authors_stat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться данные о том, \n",
    "какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка:\n",
    "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].\n",
    "Просмотрите документацию по функции pd.pivot_table с помощью вопросительного знака.\n",
    "Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. \n",
    "Используйте для этого функцию pd.pivot_table. При этом столбцы должны называться \"твердая\" и \"мягкая\", \n",
    "а индексами должны быть фамилии авторов. \n",
    "Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy.\n",
    "Назовите полученный датасет book_info и сохраните его в формат pickle под названием \"book_info.pkl\". \n",
    "Затем загрузите из этого файла датафрейм и назовите его book_info2. \n",
    "Удостоверьтесь, что датафреймы book_info и book_info2 идентичны.\n",
    "\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "authors_price['cover'] = ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']\n",
    "book_info = pd.pivot_table(authors_price, index=['author_name'], columns='cover', aggfunc='sum', values='price', fill_value=0).reset_index()\n",
    "book_info.columns.name = None               \n",
    "book_info = book_info.reset_index(drop=True) \n",
    "book_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_info.pkl', 'wb') as f:\n",
    "    pickle.dump(book_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_info.pkl', 'rb') as f:\n",
    "    book_info2 = pd.DataFrame(pickle.load(f))\n",
    "\n",
    "book_info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
